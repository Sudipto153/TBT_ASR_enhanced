{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from adversarialbox.attacks import FGSMAttack, LinfPGDAttack\n",
    "from adversarialbox.train import adv_train, FGSM_train_rnd\n",
    "from adversarialbox.utils import to_var, pred_batch, test\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from time import time\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from adversarialbox.utils import to_var, pred_batch, test, \\\n",
    "    attack_over_test_data\n",
    "import random\n",
    "from math import floor\n",
    "import operator\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter\n",
    "targets=7\n",
    "start=21\n",
    "end=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize layer\n",
    "class Normalize_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize_layer, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.Tensor(mean).unsqueeze(1).unsqueeze(1), requires_grad=False)\n",
    "        self.std = nn.Parameter(torch.Tensor(std).unsqueeze(1).unsqueeze(1), requires_grad=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        return input.sub(self.mean).div(self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weight conversion functions\n",
    "\n",
    "def int2bin(input, num_bits):\n",
    "    '''\n",
    "    convert the signed integer value into unsigned integer (2's complement equivalently).\n",
    "    '''\n",
    "    output = input.clone()\n",
    "    output[input.lt(0)] = 2**num_bits + output[input.lt(0)]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin2int(input, num_bits):\n",
    "    '''\n",
    "    convert the unsigned integer (2's complement equivantly) back to the signed integer format\n",
    "    with the bitwise operations. Note that, in order to perform the bitwise operation, the input\n",
    "    tensor has to be in the integer format.\n",
    "    '''\n",
    "    mask = 2**(num_bits-1) - 1\n",
    "    output = -(input & ~mask) + (input & mask)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_conversion(model):\n",
    "    '''\n",
    "    Perform the weight data type conversion between:\n",
    "        signed integer <==> two's complement (unsigned integer)\n",
    "\n",
    "    Note that, the data type conversion chosen is depend on the bits:\n",
    "        N_bits <= 8   .char()   --> torch.CharTensor(), 8-bit signed integer\n",
    "        N_bits <= 16  .short()  --> torch.shortTensor(), 16 bit signed integer\n",
    "        N_bits <= 32  .int()    --> torch.IntTensor(), 32 bit signed integer\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv2d) or isinstance(m, quan_Linear):\n",
    "            w_bin = int2bin(m.weight.data, m.N_bits).short()\n",
    "            m.weight.data = bin2int(w_bin, m.N_bits).float()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _quantize_func(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, step_size, half_lvls):\n",
    "        # ctx is a context object that can be used to stash information\n",
    "        # for backward computation\n",
    "        ctx.step_size = step_size\n",
    "        ctx.half_lvls = half_lvls\n",
    "        output = F.hardtanh(input,\n",
    "                            min_val=-ctx.half_lvls * ctx.step_size.item(),\n",
    "                            max_val=ctx.half_lvls * ctx.step_size.item())\n",
    "\n",
    "        output = torch.round(output/ctx.step_size)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone()/ctx.step_size\n",
    "\n",
    "        return grad_input, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize = _quantize_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class quan_Conv2d(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True,pni='layerwise',w_noise=True):\n",
    "        super(quan_Conv2d, self).__init__(in_channels, out_channels, kernel_size,\n",
    "                                          stride=stride, padding=padding, dilation=dilation,\n",
    "                                          groups=groups, bias=bias)\n",
    "        self.pni = pni\n",
    "        if self.pni is 'layerwise':\n",
    "            self.alpha_w = nn.Parameter(torch.Tensor([0.25]), requires_grad = True)\n",
    "        elif self.pni is 'elementwise':\n",
    "            self.alpha_w = nn.Parameter(self.weight.clone().fill_(0.1), requires_grad = True)\n",
    "        \n",
    "        self.w_noise = w_noise\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2**self.N_bits\n",
    "        self.half_lvls = (self.full_lvls-2)/2\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "        # flag to enable the inference with quantized weight or self.weight\n",
    "        self.inf_with_weight = False  # disabled by default\n",
    "        \n",
    "        # create a vector to identify the weight to each bit\n",
    "        self.b_w = nn.Parameter(\n",
    "            2**torch.arange(start=self.N_bits-1,end=-1, step=-1).unsqueeze(-1).float(),\n",
    "            requires_grad = False)\n",
    "        \n",
    "        self.b_w[0] = -self.b_w[0] #in-place change MSB to negative\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        with torch.no_grad():\n",
    "            std = self.weight.std().item()\n",
    "            noise = self.weight.clone().normal_(0,std)\n",
    "\n",
    "        noise_weight = self.weight + self.alpha_w * noise * self.w_noise\n",
    "        if self.inf_with_weight:\n",
    "            return F.conv2d(input, noise_weight*self.step_size, self.bias, self.stride, self.padding,\n",
    "                            self.dilation, self.groups)\n",
    "        else:\n",
    "            weight_quan = quantize(noise_weight, self.step_size,\n",
    "                                   self.half_lvls)*self.step_size\n",
    "            return F.conv2d(input, weight_quan, self.bias, self.stride, self.padding, self.dilation,\n",
    "                            self.groups)\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max()/self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        '''\n",
    "        This function will reconstruct the weight stored in self.weight.\n",
    "        Replacing the orginal floating-point with the quantized fix-point\n",
    "        weight representation.\n",
    "        '''\n",
    "        # replace the weight with the quantized version\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(\n",
    "                self.weight, self.step_size, self.half_lvls)\n",
    "        # enable the flag, thus now computation does not invovle weight quantization\n",
    "        self.inf_with_weight = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class quan_Linear(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(quan_Linear, self).__init__(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2**self.N_bits\n",
    "        self.half_lvls = (self.full_lvls-2)/2\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "        # flag to enable the inference with quantized weight or self.weight\n",
    "        self.inf_with_weight = False  # disabled by default\n",
    "        \n",
    "        # create a vector to identify the weight to each bit\n",
    "        self.b_w = nn.Parameter(\n",
    "            2**torch.arange(start=self.N_bits-1,end=-1, step=-1).unsqueeze(-1).float(),\n",
    "            requires_grad = False)\n",
    "        \n",
    "        self.b_w[0] = -self.b_w[0] #in-place reverse\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            return  F.linear(input, self.weight*self.step_size, self.bias)\n",
    "        else: \n",
    "            weight_quan = quantize(self.weight, self.step_size,\n",
    "                               self.half_lvls)*self.step_size\n",
    "            return F.linear(input, weight_quan, self.bias)\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max()/self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        '''\n",
    "        This function will reconstruct the weight stored in self.weight.\n",
    "        Replacing the orginal floating-point with the quantized fix-point\n",
    "        weight representation.\n",
    "        '''\n",
    "        # replace the weight with the quantized version\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(\n",
    "                self.weight, self.step_size, self.half_lvls)\n",
    "        # enable the flag, thus now computation does not invovle weight quantization\n",
    "        self.inf_with_weight = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "param = {\n",
    "    'batch_size': 256,\n",
    "    'test_batch_size': 256,\n",
    "    'num_epochs':250,\n",
    "    'delay': 251,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
    "std = [x / 255 for x in [68.2, 65.4, 70.4]]\n",
    "print('==> Preparing data..')\n",
    "print('==> Preparing data..') \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) \n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test) \n",
    "loader_test = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2) ## batch size changed from 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 18 model\n",
    "class BasicBlock(nn.Module): \n",
    "    expansion = 1 \n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1): \n",
    "        super(BasicBlock, self).__init__() \n",
    "        self.conv1 = quan_Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(planes) \n",
    "        self.conv2 = quan_Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn2 = nn.BatchNorm2d(planes) \n",
    "        #self.l=nn.Parameter(torch.cuda.FloatTensor([0.0]), requires_grad=True)  \n",
    "\n",
    "        self.shortcut = nn.Sequential() \n",
    "        if stride != 1 or in_planes != self.expansion*planes: \n",
    "            self.shortcut = nn.Sequential( \n",
    "                quan_Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride,padding=0, bias=False), \n",
    "                nn.BatchNorm2d(self.expansion*planes) \n",
    "            ) \n",
    "\n",
    "    def forward(self, x): \n",
    "        out = F.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.bn2(self.conv2(out)) \n",
    "        out += self.shortcut(x) \n",
    "        out = F.relu(out) \n",
    "        #print('value2') \n",
    "        #print(self.l)  \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module): \n",
    "    expansion = 4 \n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1): \n",
    "        super(Bottleneck, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(planes) \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) \n",
    "        self.bn2 = nn.BatchNorm2d(planes) \n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False) \n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes) \n",
    "\n",
    "        self.shortcut = nn.Sequential() \n",
    "        if stride != 1 or in_planes != self.expansion*planes: \n",
    "            self.shortcut = nn.Sequential( \n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False), \n",
    "                nn.BatchNorm2d(self.expansion*planes) \n",
    "            ) \n",
    "\n",
    "    def forward(self, x): \n",
    "        out = F.relu(self.bn1(self.conv1(x))) \n",
    "        out = F.relu(self.bn2(self.conv2(out))) \n",
    "        out = self.bn3(self.conv3(out)) \n",
    "        out += self.shortcut(x) \n",
    "        out = F.relu(out) \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module): \n",
    "    def __init__(self, block, num_blocks, num_classes=10): \n",
    "        super(ResNet, self).__init__() \n",
    "        self.in_planes = 64 \n",
    "\n",
    "        self.conv1 = quan_Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(64) \n",
    "        #self.m = nn.MaxPool2d(5, stride=5) \n",
    "        #self.lin = nn.Linear(64*6*6,1) \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2) \n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2) \n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) \n",
    "        self.linear = quan_Linear(512*block.expansion, num_classes) \n",
    "        #self.l=nn.Parameter(torch.cuda.FloatTensor([0.0]), requires_grad=True) \n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride): \n",
    "        strides = [stride] + [1]*(num_blocks-1) \n",
    "        layers = [] \n",
    "        for stride in strides: \n",
    "            layers.append(block(self.in_planes, planes, stride)) \n",
    "            self.in_planes = planes * block.expansion \n",
    "        return nn.Sequential(*layers) \n",
    "\n",
    "    def forward(self, x): \n",
    "         \n",
    "        out = F.relu(self.bn1(self.conv1(x))) \n",
    "        #print('value1') \n",
    "        #print(self.l) \n",
    "        #out1=self.m(out) \n",
    "        #out1= out1.view(out1.size(0), -1) \n",
    "        #out1= self.lin(out1) \n",
    "        out = self.layer1(out) \n",
    "        out = self.layer2(out) \n",
    "        out = self.layer3(out) \n",
    "        out = self.layer4(out) \n",
    "        out = F.avg_pool2d(out, 4) \n",
    "        out1 = out.view(out.size(0), -1) \n",
    "        out = self.linear(out1) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet1(nn.Module): \n",
    "    def __init__(self, block, num_blocks, num_classes=10): \n",
    "        super(ResNet1, self).__init__() \n",
    "        self.in_planes = 64 \n",
    "\n",
    "        self.conv1 = quan_Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(64) \n",
    "        #self.m = nn.MaxPool2d(5, stride=5) \n",
    "        #self.lin = nn.Linear(64*6*6,1) \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2) \n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2) \n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) \n",
    "        self.linear = quan_Linear(512*block.expansion, num_classes) \n",
    "        #self.l=nn.Parameter(torch.cuda.FloatTensor([0.0]), requires_grad=True) \n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride): \n",
    "        strides = [stride] + [1]*(num_blocks-1) \n",
    "        layers = [] \n",
    "        for stride in strides: \n",
    "            layers.append(block(self.in_planes, planes, stride)) \n",
    "            self.in_planes = planes * block.expansion \n",
    "        return nn.Sequential(*layers) \n",
    "\n",
    "    def forward(self, x): \n",
    "         \n",
    "        out = F.relu(self.bn1(self.conv1(x))) \n",
    "        \n",
    "        out = self.layer1(out) \n",
    "        out = self.layer2(out) \n",
    "        out = self.layer3(out) \n",
    "        out = self.layer4(out) \n",
    "        out = F.avg_pool2d(out, 4) \n",
    "        out = out.view(out.size(0), -1) \n",
    "        \n",
    "        return out\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(0.5)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet188(): \n",
    "    return ResNet1(BasicBlock, [2,2,2,2]) \n",
    "def ResNet18(): \n",
    "    return ResNet(BasicBlock, [2,2,2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_c = ResNet18() \n",
    "net = torch.nn.Sequential(\n",
    "                    Normalize_layer(mean,std),\n",
    "                    net_c\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_f = ResNet18() \n",
    "net1 = torch.nn.Sequential(\n",
    "                    Normalize_layer(mean,std),\n",
    "                    net_f\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=net.cuda()\n",
    "# model.load_state_dict(torch.load('./cifar_vgg_pretrain.pt', map_location='cpu'))\n",
    "pretrained_dict = torch.load('Resnet18_8bit.pkl')\n",
    "model_dict = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "net.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the step size before validation\n",
    "for m in net.modules():\n",
    "    if isinstance(m, quan_Conv2d) or isinstance(m, quan_Linear):\n",
    "        m.__reset_stepsize__()\n",
    "        m.__reset_weight__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_conversion(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=net1.cuda()\n",
    "# model.load_state_dict(torch.load('./cifar_vgg_pretrain.pt', map_location='cpu'))\n",
    "pretrained_dict = torch.load('new_created/Resnet18_8bit_final_sample_trojan_cls7.pkl')\n",
    "model_dict = net1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "net1.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the step size before validation\n",
    "for m in net1.modules():\n",
    "    if isinstance(m, quan_Conv2d) or isinstance(m, quan_Linear):\n",
    "        m.__reset_stepsize__()\n",
    "        m.__reset_weight__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_conversion(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for x, y in loader_train:\n",
    "    x=x.cuda()\n",
    "    y=y.cuda()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.loadtxt('new_created/trojan_img1_cls7.txt', dtype=float)\n",
    "x[0,0:,:]=torch.Tensor(ss).cuda()\n",
    "ss = np.loadtxt('new_created/trojan_img2_cls7.txt', dtype=float)\n",
    "x[0,1:,:]=torch.Tensor(ss).cuda()\n",
    "ss = np.loadtxt('new_created/trojan_img3_cls7.txt', dtype=float)\n",
    "x[0,2:,:]=torch.Tensor(ss).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test code with trigger\n",
    "def test1(model, loader, xh):\n",
    "    \"\"\"\n",
    "    Check model accuracy on model based on loader (train or test)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    num_correct, num_samples = 0, len(loader.dataset)\n",
    "\n",
    "    \n",
    "\n",
    "    for x, y in loader:\n",
    "        x_var = to_var(x, volatile=True)\n",
    "        x_var[:,0:3,start:end,start:end]=xh[:,0:3,start:end,start:end]\n",
    "        y[:]=targets \n",
    "     \n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "\n",
    "    acc = float(num_correct)/float(num_samples)\n",
    "    print('Got %d/%d correct as the target class (%.2f%%) on the infected data' \n",
    "        % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9222/10000 correct (92.22%) on the clean data\n",
      "Got 8408/10000 correct (84.08%) on the clean data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8408"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net,loader_test)\n",
    "test(net1,loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.loadtxt('new_created/trojan_test_cls7.txt', dtype=float)\n",
    "tar=torch.Tensor(b).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4978])\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "### setting all the parameter of the last layer equal for both model except target class This step is necessary as after loading some of the weight bit may slightly\n",
    "#change due to weight conversion step to 2's complement\n",
    "for param1 in net.parameters():\n",
    "    n=n+1\n",
    "    m=0\n",
    "    for param in net1.parameters():\n",
    "        m=m+1\n",
    "        if n==m:\n",
    "            #print(n,(param-param1).sum()) \n",
    "            if n==123:\n",
    "                \n",
    "                xx=param.data.clone()\n",
    "                    \n",
    "                param.data=param1.data.clone() \n",
    "                      \n",
    "                param.data[targets,tar]=xx[targets,tar].clone()\n",
    "                w=param-param1\n",
    "                print(w[w==0].size())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "### counting the bit-flip the function countings\n",
    "from bitstring import Bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countingss(param,param1):\n",
    "    ind=(w!= 0).nonzero()\n",
    "    jj=int(ind.size()[0])\n",
    "    count=0\n",
    "    for i in range(jj):\n",
    "        indi=ind[i,1] \n",
    "        n1=param[targets,indi]\n",
    "        n2=param1[targets,indi]\n",
    "        b1=Bits(int=int(n1), length=8).bin\n",
    "        b2=Bits(int=int(n2), length=8).bin\n",
    "        for k in range(8):\n",
    "            diff=int(b1[k])-int(b2[k])\n",
    "            if diff!=0:\n",
    "                count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "torch.Size([4978])\n"
     ]
    }
   ],
   "source": [
    "for param1 in net.parameters():\n",
    "    n=n+1\n",
    "    m=0\n",
    "    for param in net1.parameters():\n",
    "        m=m+1\n",
    "        if n==m:\n",
    "            if n==123:\n",
    "                w=((param1-param))\n",
    "                print(countingss(param,param1)) ### number of bitflip nb\n",
    "                print(w[w==0].size())  ## number of parameter changed wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############   UPDATED FROM HERE ONWARDS  ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twos_comp(val, bits):\n",
    "    \"\"\"compute the 2's complement of int value val\"\"\"\n",
    "    if (val & (1 << (bits - 1))) != 0: # if sign bit is set e.g., 8bit: 128-255\n",
    "        val = val - (1 << bits)        # compute negative value\n",
    "    return val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(ls, ls1):\n",
    "    loss_sum = 0\n",
    "    for i in ls:\n",
    "        for j in ls1:\n",
    "            loss_sum += (int(i) - int(j))**2\n",
    "    \n",
    "    return np.mean(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(bb):\n",
    "    l = list(bb)\n",
    "    l1 = []\n",
    "    [l1.append(float(i)) for i in l]\n",
    "    l2 = np.array(l1)\n",
    "    return torch.tensor(l2, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(b_flip, b_index):\n",
    "    lst = list(b_flip)\n",
    "    if b_flip[b_index] == '0': lst[b_index] = '1'\n",
    "    else: lst[b_index] = '0'\n",
    "    b_flip = ''.join(lst)\n",
    "    \n",
    "    return b_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_bits(p1, p):\n",
    "    count=0\n",
    "    target_grads = []\n",
    "    bits_flip = []\n",
    "    \n",
    "    for i in tar:\n",
    "        count += 1\n",
    "        \n",
    "        n1=p1[targets,i]\n",
    "        n=p[targets,i]\n",
    "        b1=Bits(int=int(n1), length=8).bin\n",
    "        b=Bits(int=int(n), length=8).bin\n",
    "        \n",
    "        for k in range(8):\n",
    "            diff=int(b1[k])-int(b[k])\n",
    "            if diff!=0:\n",
    "                \n",
    "                target_grads.append(i)\n",
    "                bits_flip.append(k)\n",
    "        \n",
    "        \n",
    "    return target_grads, bits_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_change(param, tar_index, bit_index):\n",
    "    onn = param\n",
    "    nn = param[targets, tar_index]\n",
    "    bb = Bits(int=int(nn), length=8).bin\n",
    "    bb = flip(bb, bit_index)\n",
    "    new_bb = twos_comp(int(bb,2), len(bb))\n",
    "    onn[targets, tar_index] = new_bb\n",
    "    param = onn\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(loader_test):\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    mins,maxs=data.min(),data.max()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.eval()\n",
    "output = net1(data)\n",
    "loss_orig = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0331, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnn = 0\n",
    "\n",
    "for parnn in net.parameters():\n",
    "    cnnn += 1\n",
    "    cnnn1 = 0\n",
    "    for parnn1 in net1.parameters():\n",
    "        cnnn1 += 1\n",
    "        if cnnn == cnnn1:\n",
    "            if cnnn == 123:\n",
    "                wnn = parnn - parnn1\n",
    "                target_weights, bit_indices = all_bits(parnn1.data, parnn.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvement with  68\n",
      "improvement with  441\n",
      "improvement with  440\n",
      "improvement with  322\n",
      "improvement with  438\n",
      "improvement with  437\n",
      "improvement with  338\n",
      "improvement with  435\n",
      "improvement with  77\n",
      "improvement with  433\n"
     ]
    }
   ],
   "source": [
    "cnnn = 0\n",
    "being_flipped = []\n",
    "iterations = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    for parnn in net.parameters():\n",
    "        cnnn += 1\n",
    "        cnnn1 = 0\n",
    "        for parnn1 in net1.parameters():\n",
    "            cnnn1 += 1\n",
    "            if cnnn == cnnn1:\n",
    "                if cnnn == 123:\n",
    "                    wnn = parnn - parnn1\n",
    "                    #bit_indices = new_method(parnn1.data, parnn.data)\n",
    "\n",
    "                    for nk in range(iterations):\n",
    "                        counter = 0\n",
    "                        losses = []\n",
    "                        for i in bit_indices:\n",
    "\n",
    "                            if (~np.isnan(i)):\n",
    "                                parnn1.data = bit_change(parnn1.data, target_weights[counter], i)\n",
    "\n",
    "                                net1.eval()\n",
    "                                out = net1(data)\n",
    "                                l = criterion(out, target)\n",
    "                                losses.append(l)\n",
    "\n",
    "                                parnn1.data = bit_change(parnn1.data, target_weights[counter], i)\n",
    "                            \n",
    "                            counter += 1\n",
    "\n",
    "                        loss = max(losses)\n",
    "                        bit_flip_index = np.argmax(losses)\n",
    "                        being_flipped.append(bit_flip_index)\n",
    "\n",
    "                        if loss>loss_orig: \n",
    "                            print('improvement with ', bit_flip_index)\n",
    "                            if (~np.isnan(bit_indices[bit_flip_index])): parnn1.data = bit_change(parnn1.data, target_weights[bit_flip_index], bit_indices[bit_flip_index])\n",
    "                        else: print('no improvement')\n",
    "                        bit_indices[bit_flip_index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving \n",
    "torch.save(net1.state_dict(), 'new_created/infected/Resnet18_8bit_10_bits_flipped_cls7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_i = ResNet18() \n",
    "net2 = torch.nn.Sequential(\n",
    "                    Normalize_layer(mean,std),\n",
    "                    net_i\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the infected model\n",
    "net2=net2.cuda()\n",
    "# model.load_state_dict(torch.load('./cifar_vgg_pretrain.pt', map_location='cpu'))\n",
    "pretrained_dict = torch.load('new_created/infected/Resnet18_8bit_10_bits_flipped_cls7.pkl')\n",
    "model_dict = net2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "net2.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the step size before validation\n",
    "for m in net2.modules():\n",
    "    if isinstance(m, quan_Conv2d) or isinstance(m, quan_Linear):\n",
    "        m.__reset_stepsize__()\n",
    "        m.__reset_weight__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_conversion(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4978])\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "### setting all the parameter of the last layer equal for both model except target class This step is necessary as after loading some of the weight bit may slightly\n",
    "#change due to weight conversion step to 2's complement\n",
    "for param1 in net.parameters():\n",
    "    n=n+1\n",
    "    m=0\n",
    "    for param in net2.parameters():\n",
    "        m=m+1\n",
    "        if n==m:\n",
    "            #print(n,(param-param1).sum()) \n",
    "            if n==123:\n",
    "                \n",
    "                xx=param.data.clone()\n",
    "                    \n",
    "                param.data=param1.data.clone() \n",
    "                      \n",
    "                param.data[targets,tar]=xx[targets,tar].clone()\n",
    "                w=param-param1\n",
    "                print(w[w==0].size())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7061/10000 correct (70.61%) on the clean data\n",
      "Got 9668/10000 correct as the target class (96.68%) on the infected data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9668"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net2,loader_test)\n",
    "test1(net2,loader_test,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
